
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - kafka-net
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 2181 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    ports:
      - "9092:9092"
    networks:
      - kafka-net
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --list --bootstrap-server localhost:9092 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    command: >
      sh -c "/etc/confluent/docker/run &&
      sleep 10 &&
      kafka-topics --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic tiksup &&
      tail -f /dev/null"


  redis:
    image: redis:7.4.0-alpine
    ports:
      - "6379:6379"
    networks:
      - kafka-net

  mongo:
    image: mongo:8.0.1-rc0-noble
    environment:
      - MONGO_INITDB_ROOT_USERNAME=${MONGO_USER}
      - MONGO_INITDB_ROOT_PASSWORD=${MONGO_PASSWORD}
    ports:
      - "27017:27017"
    networks:
      - kafka-net
    healthcheck:
      test: ["CMD-SHELL", "echo 'db.runCommand(\"ping\").ok' | mongo localhost:27017/test --quiet"]
      interval: 30s
      timeout: 10s
      retries: 3
  
  mongo-builder:
    image: mongo:8.0.1-rc0-noble
    volumes:
      - ./movies.json:/app/movies.json:ro
    command: >
      mongoimport -u ${MONGO_USER} -p ${MONGO_PASSWORD} --authenticationDatabase admin --host mongo --db ${MONGO_DB} --collection ${MONGO_COLLECTION} --type json --file /app/movies.json --jsonArray
    restart: "no"
    networks:
      - kafka-net

  postgres:
    image: postgres:17-alpine3.20
    environment:
      - POSTGRES_USER=${PG_USER}
      - POSTGRES_PASSWORD=${PG_PASSWORD}
      - POSTGRES_DB=${PG_NAME}
    networks:
      - kafka-net
    ports:
      - "5432:5432"

  spark-master:
    image: bitnami/spark:latest
    environment:
      - SPARK_MODE=master
    networks:
      - kafka-net
    ports:
      - "7077:7077"
      - "8080:8080"

  spark-worker:
    image: bitnami/spark:latest
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    networks:
      - kafka-net

  processor:
    build: ./processor
    depends_on:
      - spark-master
      - spark-worker
      - redis
    environment:
      - REDIS_HOST=${REDIS_HOST}
      - REDIS_PORT=${REDIS_PORT}
      - SPARK_HOST=${SPARK_HOST}
      - SPARK_PORT=${SPARK_PORT}
    restart: always
    networks:
      - kafka-net
    ports:
      - "8000:8000"

  worker:
    build: ./worker
    environment:
      - SECRET_KEY=${SECRET_KEY}
      - PORT=${WORKER_PORT}
      - PROCESSOR_URL=${PROCESSOR_URL}
      - PG_HOST=${PG_HOST}
      - PG_PORT=${PG_PORT}
      - PG_NAME=${PG_NAME}
      - PG_USER=${PG_USER}
      - PG_PASSWORD=${PG_PASSWORD}
      - KAFKA_SERVER=${KAFKA_SERVER}
      - KAFKA_TOPIC=${KAFKA_TOPIC}
      - MONGO_HOST=${MONGO_HOST}
      - MONGO_PORT=${MONGO_PORT}
      - MONGO_USER=${MONGO_USER}
      - MONGO_PASSWORD=${MONGO_PASSWORD}
      - MONGO_DB=${MONGO_DB}
      - MONGO_COLLECTION=${MONGO_COLLECTION}
    depends_on:
      - mongo
      - postgres
      - kafka
    restart: always
    networks:
      - kafka-net
    ports:
      - "${WORKER_PORT}:${WORKER_PORT}"

  gateway:
    build: ./gateway
    depends_on:
      - redis
    environment:
      - SECRET_KEY=${SECRET_KEY}
      - PORT=${GATEWAY_PORT}
      - KAFKA_SERVER=${KAFKA_SERVER}
      - KAFKA_TOPIC=${KAFKA_TOPIC}
      - WORKER_URL=${WORKER_URL}
      - GRPC_HOST=${GRPC_HOST}
      - REDIS_HOST=${REDIS_HOST}
      - REDIS_PORT=${REDIS_PORT}
    restart: always
    networks:
      - kafka-net
    ports:
      - "${GATEWAY_PORT}:${GATEWAY_PORT}"

  client:
    build:
      context: ./client
      dockerfile: Dockerfile
    environment:
      - PORT=${CLIENT_PORT}
      - GATEWAY_URL=${GATEWAY_URL}
    depends_on:
      - gateway
    restart: always
    networks:
      - kafka-net
    ports:
      - "${CLIENT_PORT}:${CLIENT_PORT}"


networks:
  kafka-net:
    driver: bridge
